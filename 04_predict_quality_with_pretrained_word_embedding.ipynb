{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predict the quality of Wine based on the description with pre trained Word Embeddings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/winemag-data-130k-v2.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# split points into binary label (80-89 = bad, 90-99 = good)\n",
    "df['label'] = df['points'].apply(lambda x: 'good' if x > 89 else 'bad')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from util import cleanse_data\n",
    "\n",
    "clean_txt = cleanse_data(df)\n",
    "df['clean_desc'] = clean_txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for col in df.clean_desc:\n",
    "    word_list = col.split(' ')\n",
    "    corpus.append(word_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['clean_desc']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Note: This will download the google news model (which is around 1.7GB) so only run this once. Afterwards it will be saved to your disk for future usage.\n",
    "import gensim.downloader as api\n",
    "\n",
    "#model = api.load('word2vec-google-news-300')\n",
    "#model.save('embeddings\\google-news-300.model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "google_news_model = KeyedVectors.load('embeddings\\google-news-300.model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sentence_to_vector(sentence, word_embedding):\n",
    "    vector = []\n",
    "    for word in sentence.split():\n",
    "        if word in word_embedding:\n",
    "            vector.append(word_embedding[word])\n",
    "    return np.mean(vector, axis=0)\n",
    "\n",
    "\n",
    "train_vectors = [sentence_to_vector(sentence, google_news_model) for sentence in X_train]\n",
    "test_vectors = [sentence_to_vector(sentence, google_news_model) for sentence in X_test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6922485093287171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "nb_model = BernoulliNB()\n",
    "nb_model.fit(train_vectors, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(test_vectors)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the google news word embedding does predict the quality slightly better than the custom word embedding. However, the tfidf approach still seems to work better for this use case. We could try other word embeddings or also other models to maybe find a better solution. But for this assignment were fine with the insights that we got by now. In the next step we try to predict the reviwers based on the review description. -> See Notebook 05."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}